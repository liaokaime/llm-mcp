# LLM MCP Server

æä¾›é€šç”¨ AI èƒ½åŠ›çš„ Model Context Protocol (MCP) æœåŠ¡å™¨ã€‚å®ƒä½¿ç”¨ OpenAI SDK é€šè¿‡ç»Ÿä¸€æ¥å£è®¿é—®ä»»ä½•å…¼å®¹ OpenAI çš„ APIï¼ˆå¦‚ OpenRouter, OpenAI, DeepSeek, LocalAI ç­‰ï¼‰ã€‚æœ¬é¡¹ç›®åŸºäº Node.js å’Œ TypeScript æ„å»ºã€‚

## åŠŸèƒ½ç‰¹æ€§

- **query_model**ï¼šç”±ä»»ä½•å…¼å®¹ OpenAI çš„æä¾›å•†é©±åŠ¨çš„ AI åŠ©æ‰‹
- ä½¿ç”¨ OpenAI SDK ç¡®ä¿å¹¿æ³›çš„å…¼å®¹æ€§
- å®Œæ•´çš„ TypeScript æ”¯æŒï¼ŒåŒ…å«ä¸¥æ ¼çš„ç±»å‹æ£€æŸ¥
- å¯è‡ªå®šä¹‰ Base URL ä»¥æ”¯æŒä»»ä½•æä¾›å•†

## å‰ç½®è¦æ±‚

- [Node.js](https://nodejs.org/) (v18.0.0+)
- npm, pnpm, æˆ– yarn
- ä½ é€‰æ‹©çš„æä¾›å•†çš„ API Key

## å®‰è£…

### ä»æºç å®‰è£…

1. å…‹éš†æ­¤ä»“åº“ï¼š

```bash
git clone <repository-url>
cd llm-mcp
```

2. å®‰è£…ä¾èµ–ï¼š

```bash
npm install
# æˆ–è€…
pnpm install
# æˆ–è€…
yarn install
```

3. æ„å»ºé¡¹ç›®ï¼š

```bash
npm run build
```

4. è®¾ç½®ç¯å¢ƒå˜é‡ï¼š

```bash
export OPENAI_API_KEY=your_api_key_here
export OPENAI_MODEL=openai/gpt-4o-mini  # å¯é€‰ï¼Œé»˜è®¤ä¸º openai/gpt-4o-mini
export OPENAI_BASE_URL=https://openrouter.ai/api/v1 # å¯é€‰ï¼Œé»˜è®¤ä¸º OpenRouter
```

## ä½¿ç”¨æ–¹æ³•

### å¯åŠ¨æœåŠ¡å™¨

```bash
# é¦–å…ˆè®¾ç½®ç¯å¢ƒå˜é‡
export OPENAI_API_KEY=your_api_key_here
export OPENAI_MODEL=openai/gpt-4o-mini  # å¯é€‰
export OPENAI_BASE_URL=https://api.openai.com/v1 # å¯é€‰ï¼Œä¾‹å¦‚ç”¨äºå®˜æ–¹ OpenAI

# å¼€å‘æ¨¡å¼ï¼ˆå¸¦æœ‰ç›‘å¬å’Œçƒ­é‡è½½ï¼‰
npm run dev

# ç”Ÿäº§æ¨¡å¼ï¼ˆéœ€è¦å…ˆæ„å»ºï¼‰
npm run build
npm start
```

### ä»£ç è´¨é‡

```bash
# æ ¼å¼åŒ–ä»£ç 
npm run format

# ä»£ç æ£€æŸ¥
npm run lint

# æ„å»º TypeScript
npm run build
```

## MCP å·¥å…·

### query_model

ç”±ä½ é…ç½®çš„ LLM æä¾›å•†é©±åŠ¨çš„ AI åŠ©æ‰‹ã€‚

**å‚æ•°ï¼š**

- `prompt` (å¿…å¡«)ï¼šä½ è¦å‘é€ç»™ AI æ¨¡å‹çš„é—®é¢˜æˆ–è¯·æ±‚ã€‚

**ç¤ºä¾‹ï¼š**

```json
{
  "name": "query_model",
  "arguments": {
    "prompt": "é‡å­è®¡ç®—çš„æœ€æ–°è¿›å±•æ˜¯ä»€ä¹ˆï¼Ÿ"
  }
}
```

**èƒ½åŠ›ï¼š**

- ğŸ¤– è®¿é—®ä»»ä½•å…¼å®¹ OpenAI çš„æ¨¡å‹
- âš¡ å¿«é€Ÿå¯é çš„ API
- ğŸ“Š åŒ…å« token è®¡æ•°çš„ä½¿ç”¨å…ƒæ•°æ®
- ğŸ”„ é€šè¿‡ç¯å¢ƒå˜é‡è½»æ¾åˆ‡æ¢æ¨¡å‹

## å¯ç”¨æ¨¡å‹

æœ¬æœåŠ¡å™¨æ”¯æŒä½ çš„åç«¯æä¾›çš„ä»»ä½•æ¨¡å‹ã€‚

## å¼€å‘

æœ¬é¡¹ç›®ä½¿ç”¨ Node.js å’Œ TypeScriptã€‚ä¸»è¦å¼€å‘å‘½ä»¤ï¼š

- `npm run dev` - å¯åŠ¨å¸¦æœ‰ç›‘å¬æ¨¡å¼çš„å¼€å‘æœåŠ¡å™¨ (ä½¿ç”¨ tsx)
- `npm run build` - å°† TypeScript æ„å»ºä¸º JavaScript
- `npm run lint` - ä»£ç æ£€æŸ¥
- `npm run format` - ä½¿ç”¨ Prettier æ ¼å¼åŒ–ä»£ç 

## æ•…éšœæ’é™¤

### ç¯å¢ƒå˜é‡é—®é¢˜

å¦‚æœä½ é‡åˆ°ç¯å¢ƒå˜é‡é”™è¯¯ï¼š

1. **éªŒè¯ä½ çš„ç¯å¢ƒå˜é‡æ˜¯å¦å·²è®¾ç½®**ï¼š

   ```bash
   echo $OPENAI_API_KEY
   echo $OPENAI_MODEL
   echo $OPENAI_BASE_URL
   ```

2. **å¯¹äº MCP Inspector æµ‹è¯•**ï¼Œç¡®ä¿ API Key è®¾ç½®åœ¨åŒä¸€ä¸ªç»ˆç«¯ä¸­ï¼š

   ```bash
   export OPENAI_API_KEY=your_api_key_here
   export OPENAI_MODEL=openai/gpt-4o-mini
   npx @modelcontextprotocol/inspector npx tsx src/server.ts
   ```

3. **æ£€æŸ¥æœåŠ¡å™¨æ—¥å¿—**ï¼šå½“æœåŠ¡å™¨å¯åŠ¨æ—¶ï¼Œå®ƒä¼šæ˜¾ç¤º `(API Key: configured)` æ¥ç¡®è®¤ä½ çš„ Key å·²åŠ è½½ã€‚

## æ”¯æŒ

- [Model Context Protocol](https://modelcontextprotocol.io/)

## Claude Desktop é…ç½®

è¦åœ¨ Claude Desktop ä¸­ä½¿ç”¨æ­¤ MCP æœåŠ¡å™¨ï¼Œè¯·å°†å…¶æ·»åŠ åˆ°ä½ çš„ Claude é…ç½®ä¸­ï¼š

### macOS/Linux

ç¼–è¾‘ä½ çš„ Claude é…ç½®æ–‡ä»¶ï¼š
`~/Library/Application Support/Claude/claude_desktop_config.json` (macOS) æˆ–
`~/.config/Claude/claude_desktop_config.json` (Linux)ï¼š

```json
{
  "mcpServers": {
    "llm": {
      "command": "node",
      "args": ["/absolute/path/to/llm-mcp/dist/server.js"],
      "env": {
        "OPENAI_API_KEY": "your_api_key_here",
        "OPENAI_MODEL": "openai/gpt-4o-mini",
        "OPENAI_BASE_URL": "https://openrouter.ai/api/v1"
      }
    }
  }
}
```

### Windows

ç¼–è¾‘ä½ çš„ Claude é…ç½®æ–‡ä»¶ï¼š
`%APPDATA%\Claude\claude_desktop_config.json`ï¼š

```json
{
  "mcpServers": {
    "llm": {
      "command": "node",
      "args": ["C:\\path\\to\\llm-mcp\\dist\\server.js"],
      "env": {
        "OPENAI_API_KEY": "your_api_key_here",
        "OPENAI_MODEL": "openai/gpt-4o-mini",
        "OPENAI_BASE_URL": "https://openrouter.ai/api/v1"
      }
    }
  }
}
```

### æœ¬åœ°å¼€å‘

ç”¨äºä½¿ç”¨ tsx è¿›è¡Œçƒ­é‡è½½å¼€å‘ï¼š

```json
{
  "mcpServers": {
    "llm": {
      "command": "npx",
      "args": ["tsx", "/absolute/path/to/llm-mcp/src/server.ts"],
      "env": {
        "OPENAI_API_KEY": "your_api_key_here",
        "OPENAI_MODEL": "openai/gpt-4o-mini"
      }
    }
  }
}
```

## è´¡çŒ®

1. Fork ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯
3. æäº¤ä½ çš„æ›´æ”¹
4. æ ¼å¼åŒ–ä»£ç ï¼š`npm run format`
5. ä»£ç æ£€æŸ¥ï¼š`npm run lint`
6. æ„å»ºï¼š`npm run build`
7. æäº¤ Pull Request

## è®¸å¯è¯

MIT License - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚
